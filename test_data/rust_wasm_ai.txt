Rust is a multi-paradigm, general-purpose programming language that emphasizes performance, type safety, and concurrency. It enforces memory safety—meaning that all references point to valid memory—without a garbage collector. To simultaneously enforce memory safety and prevent data races, its "borrow checker" tracks the object lifetime of all references in a program during compilation. Rust is popular for systems programming but also offers high-level features like functional programming constructs.

WebAssembly (Wasm) is a binary instruction format for a stack-based virtual machine. Wasm is designed as a portable compilation target for programming languages, enabling deployment on the web for client and server applications. It allows code written in languages like C, C++, C#, and Rust to run on the web at near-native speed. WebAssembly is designed to coexist with JavaScript, allowing both to work together.

Artificial intelligence (AI) is intelligence—perceiving, synthesizing, and inferring information—demonstrated by machines, as opposed to intelligence displayed by non-human animals and humans. Example tasks in which this is done include speech recognition, computer vision, translation between (natural) languages, as well as other mappings of inputs.

Vector databases are databases that store data as high-dimensional vectors, which are mathematical representations of features or attributes. These vectors are generated by machine learning models, such as embedding models, which transform complex data like text, images, or audio into numerical arrays. This allows for semantic search, where results are based on the meaning of the query rather than exact keyword matches.

In the context of Local Mind, we are combining these technologies. We use Rust to handle the heavy lifting of text processing and vector storage. We compile this Rust code to WebAssembly so it can run directly in the user's browser. We use a BERT-based model (specifically all-MiniLM-L6-v2) to generate embeddings for text chunks. This enables a privacy-first search engine where data never leaves the user's device.

The borrow checker is Rust's most unique feature. It ensures that there is only one mutable reference to a piece of data at a time, or multiple immutable references. This prevents data races at compile time. While it has a steep learning curve, it eliminates entire classes of bugs that are common in C and C++.

Transformers are a type of deep learning model that has revolutionized natural language processing (NLP). They use a mechanism called "attention" to weigh the influence of different parts of the input data. BERT (Bidirectional Encoder Representations from Transformers) is a specific transformer model designed to pre-train deep bidirectional representations from unlabeled text.

Running AI in the browser is becoming increasingly feasible thanks to WebAssembly and WebGPU. Frameworks like Candle (written in Rust) allow us to run quantized models efficiently on the client side. This reduces server costs and improves user privacy.

Memory management in Rust is manual but automated by the compiler. You don't call free(), but you also don't have a garbage collector pausing your program. Instead, memory is freed when variables go out of scope. This deterministic destruction is crucial for real-time systems and high-performance applications like game engines or browser components.

Semantic search differs from keyword search. If you search for "canine", a keyword search looks for the word "canine". A semantic search understands that "canine" is related to "dog" and might return documents containing "dog" even if the word "canine" is missing. This is achieved through vector embeddings, where "dog" and "canine" would have vectors that are close to each other in the high-dimensional space.
